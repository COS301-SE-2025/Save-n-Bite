# Example: Enhanced frontend-ci.yml with Grafana metrics export
# Replace your existing frontend-ci.yml with this version to enable metrics

name: Frontend

on:
  push:
    branches: [ backend, main ]
  pull_request:
    branches: [ backend, main ]

env:
  NODE_VERSION: 20

jobs:
  frontend-tests:
    runs-on: ubuntu-latest
    defaults:
      run:
        working-directory: ./save-n-bite-frontend
    
    steps:
      - name: Checkout code
        uses: actions/checkout@v4
      
      # Record workflow start time
      - name: Record workflow start time
        id: workflow_start
        run: echo "start_time=$(date +%s)" >> $GITHUB_OUTPUT
      
      - name: Setup Node
        uses: actions/setup-node@v4
        with:
          node-version: ${{env.NODE_VERSION}}
          cache: 'npm'
          cache-dependency-path: './save-n-bite-frontend/package-lock.json'
          
      - name: Install dependencies
        run: npm i
        
      - name: Run Jest with coverage
        id: jest_tests
        continue-on-error: true
        run: |
          start=$(date +%s)
          npx jest --coverage --json --outputFile=test-results.json > test_output.txt 2>&1
          exit_code=$?
          end=$(date +%s)
          duration=$((end - start))
          
          # Parse test results from JSON
          if [ -f test-results.json ]; then
            total=$(jq -r '.numTotalTests' test-results.json)
            passed=$(jq -r '.numPassedTests' test-results.json)
            failed=$(jq -r '.numFailedTests' test-results.json)
            skipped=$(jq -r '.numPendingTests' test-results.json)
            
            echo "total=$total" >> $GITHUB_OUTPUT
            echo "passed=$passed" >> $GITHUB_OUTPUT
            echo "failed=$failed" >> $GITHUB_OUTPUT
            echo "skipped=$skipped" >> $GITHUB_OUTPUT
          else
            echo "total=0" >> $GITHUB_OUTPUT
            echo "passed=0" >> $GITHUB_OUTPUT
            echo "failed=0" >> $GITHUB_OUTPUT
            echo "skipped=0" >> $GITHUB_OUTPUT
          fi
          
          echo "duration=$duration" >> $GITHUB_OUTPUT
          
          if [ $exit_code -eq 0 ]; then
            echo "status=success" >> $GITHUB_OUTPUT
          else
            echo "status=failure" >> $GITHUB_OUTPUT
          fi
          
          cat test_output.txt
          exit $exit_code
      
      - name: Extract coverage percentage
        id: coverage
        if: always()
        run: |
          if [ -f coverage/coverage-summary.json ]; then
            coverage_percent=$(jq -r '.total.lines.pct' coverage/coverage-summary.json)
            echo "percent=$coverage_percent" >> $GITHUB_OUTPUT
            echo "Frontend test coverage: $coverage_percent%"
          else
            echo "percent=0" >> $GITHUB_OUTPUT
          fi
      
      - name: Upload coverage to Codecov
        uses: codecov/codecov-action@v3
        with:
          github-token: ${{ secrets.GITHUB_TOKEN }}
          file: ./save-n-bite-frontend/coverage/lcov.info
      
      # Calculate workflow metrics
      - name: Calculate workflow metrics
        if: always()
        id: workflow_metrics
        run: |
          end_time=$(date +%s)
          start_time=${{ steps.workflow_start.outputs.start_time }}
          duration=$((end_time - start_time))
          echo "duration=$duration" >> $GITHUB_OUTPUT
          echo "status=${{ steps.jest_tests.outputs.status }}" >> $GITHUB_OUTPUT
      
      # Export metrics to Pushgateway (if configured)
      - name: Export workflow metrics
        if: always() && vars.PUSHGATEWAY_URL != ''
        continue-on-error: true
        env:
          PUSHGATEWAY_URL: ${{ vars.PUSHGATEWAY_URL }}
        run: |
          # Install dependencies
          pip3 install requests > /dev/null 2>&1 || true
          
          cd $GITHUB_WORKSPACE/monitoring/scripts
          
          # Export workflow metrics
          python3 export_metrics.py workflow \
            "${{ steps.workflow_metrics.outputs.status }}" \
            "${{ steps.workflow_metrics.outputs.duration }}" || true
          
          # Export test metrics
          python3 export_metrics.py test \
            "${{ steps.jest_tests.outputs.total }}" \
            "${{ steps.jest_tests.outputs.passed }}" \
            "${{ steps.jest_tests.outputs.failed }}" \
            "${{ steps.jest_tests.outputs.skipped }}" \
            "${{ steps.jest_tests.outputs.duration }}" \
            --app "frontend" || true
          
          # Export coverage metrics
          if [ -n "${{ steps.coverage.outputs.percent }}" ]; then
            python3 export_metrics.py coverage \
              "${{ steps.coverage.outputs.percent }}" \
              --app "frontend" || true
          fi
      
      # Fail the job if tests failed
      - name: Check test results
        if: steps.jest_tests.outputs.status == 'failure'
        run: exit 1

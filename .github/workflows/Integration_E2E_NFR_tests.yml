name: Integration, E2E and NFR Tests

on:
  push:

    branches: [ main ]
  pull_request:
    branches: [  main ]

  workflow_dispatch:
    inputs:
      run_coverage:
        description: 'Run test coverage report'
        required: false
        default: false
        type: boolean

jobs:
  test:
    runs-on: ubuntu-latest

    # Set up PostgreSQL service for testin
    services:
      postgres:
        image: postgres:15
        env:
          POSTGRES_PASSWORD: postgres
          POSTGRES_DB: test_savenbite_db
          POSTGRES_MULTIPLE_DATABASES: 'test_savenbite_db,test_nfr_db'
        options: >-
          --health-cmd pg_isready
          --health-interval 10s
          --health-timeout 5s
          --health-retries 5
        ports:
          - 5432:5432

      redis:
        image: redis:7
        options: >-
          --health-cmd "redis-cli ping"
          --health-interval 10s
          --health-timeout 5s
          --health-retries 5
        ports:
          - 6379:6379

    defaults:
      run:
        working-directory: save-n-bite-backend

    steps:
    - uses: actions/checkout@v4

    - name: Ensure static and media directories exist
      run: |
        mkdir -p static
        mkdir -p media

    - name: Set up Python
      uses: actions/setup-python@v5
      with:
        python-version: '3.11'

    - name: Install Poetry
      run: |
        curl -sSL https://install.python-poetry.org | python3 -
        echo "$HOME/.local/bin" >> $GITHUB_PATH

    - name: Cache Poetry dependencies
      uses: actions/cache@v4
      with:
        path: |
          ~/.cache/pip
          ~/.cache/pypoetry
          save-n-bite-backend/.venv
        key: ${{ runner.os }}-poetry-${{ hashFiles('save-n-bite-backend/poetry.lock') }}
        restore-keys: |
          ${{ runner.os }}-poetry-

    - name: Configure Poetry
      run: |
        poetry config virtualenvs.create true
        poetry config virtualenvs.in-project true

    - name: Install dependencies with Poetry
      run: |
        poetry install --with dev
        # Ensure all test dependencies are properly installed
        poetry run pip install model_bakery coverage pytest-html

    - name: Install PostgreSQL client (for pg_isready)
      run: |
        sudo apt-get update
        sudo apt-get install -y postgresql-client

    - name: Create test environment file
      run: |
        cat > .env << EOF
        DEBUG=True
        SECRET_KEY=test-secret-key-for-github-actions-very-long-and-secure
        DB_NAME=test_savenbite_db
        DB_USER=postgres
        DB_PASSWORD=postgres
        DB_HOST=127.0.0.1
        DB_PORT=5432
        REDIS_URL=redis://localhost:6379/0
        ALLOWED_HOSTS=localhost,127.0.0.1
        CORS_ALLOWED_ORIGINS=http://localhost:3000,http://127.0.0.1:3000

        # Disable Azure Storage for testing
        USE_AZURE_STORAGE=False
        TESTING=True
        GEOCODING_ENABLED=False
        AZURE_STORAGE_CONNECTION_STRING=UseDevelopmentStorage=true
        AZURE_CONTAINER_NAME=test-container
        EOF

    - name: Wait for services
      run: |
        # Wait for PostgreSQL
        echo "Waiting for PostgreSQL..."
        until pg_isready -h 127.0.0.1 -p 5432 -U postgres; do
          echo "PostgreSQL not ready, waiting..."
          sleep 2
        done
        echo "âœ… PostgreSQL is ready"
      

    - name: Verify Django setup
      run: |
        poetry run python -c "
        import django
        print(f'Django version: {django.get_version()}')
        try:
            import azure.storage.blob
        except ImportError:
            print('Azure storage blob: NOT AVAILABLE')
        "


    - name: Run migrations
      run: poetry run python manage.py migrate

    - name: Run Django system check
      run: poetry run python manage.py check

    - name: Clean up any existing test databases
      run: |
        export PGPASSWORD=postgres
        psql -h 127.0.0.1 -U postgres -d postgres -c "SELECT pg_terminate_backend(pid) FROM pg_stat_activity WHERE datname = 'test_save_n_bite_integration_db'" || true
        dropdb -h 127.0.0.1 -U postgres test_save_n_bite_integration_db || true
        createdb -h 127.0.0.1 -U postgres test_save_n_bite_integration_db || true

    - name: Run Tests with Cleanup
      run: |
        set -e
        # Run tests with parallel execution and proper cleanup
        poetry run python manage.py test \
          --parallel \
          --noinput \
          --test-runner="django.test.runner.DiscoverRunner" \
          --settings=config.settings.test \
          tests/ test_integration.py test_end_to_end.py test_nfr_simple.py || true
        
        # Force cleanup of any remaining connections
        export PGPASSWORD=postgres
        psql -h 127.0.0.1 -U postgres -d postgres -c "SELECT pg_terminate_backend(pid) FROM pg_stat_activity WHERE datname = 'test_save_n_bite_integration_db'" || true
        dropdb -h 127.0.0.1 -U postgres test_save_n_bite_integration_db || true
      env:
        TEST_DATABASE_NAME: test_save_n_bite_integration_db
        TEST: "true"

    # - name: Run reviews app tests only
    #   run: poetry run pytest reviews/tests.py

    # - name: Run Interactions app tests only
    #   run: poetry run pytest interactions/tests

    # - name: Run Notifications app tests only
    #   run: poetry run pytest notifications/tests.py

    # - name: Run FoodListing app tests only
    #   run: poetry run pytest food_listings/tests.py

    # - name: Run Badges app tests only
    #   run: poetry run pytest badges/tests.py

    # - name: Run Admin System app tests only
    #   run: poetry run python manage.py test admin_system

    # - name: Run Authentication app tests only
    #   run: poetry run python manage.py test authentication

    - name: Create NFR test database
      run: |
        export PGPASSWORD=postgres
        psql -h 127.0.0.1 -U postgres -c "CREATE DATABASE test_nfr_db;"
        echo "Created NFR test database"

    - name: Run Integration End to End and Non Functional Tests
      run: |
        set -e
        # Run the tests with NFR database
        export TEST_DATABASE_NAME=test_nfr_db
        poetry run python run_integration_tests.py --all --verbose || true
        
        # Force cleanup of any remaining connections
        echo "Cleaning up test database..."
        export PGPASSWORD=postgres
        
        # Kill all connections to the test database
        for i in {1..5}; do
          echo "Attempt $i to terminate connections..."
          psql -h 127.0.0.1 -U postgres -d postgres -c "SELECT pg_terminate_backend(pid) FROM pg_stat_activity WHERE datname = 'test_save_n_bite_integration_db'" || true
          
          # Check if there are still connections
          CONNS=$(psql -h 127.0.0.1 -U postgres -d postgres -t -c "SELECT count(*) FROM pg_stat_activity WHERE datname = 'test_save_n_bite_integration_db'" | tr -d '[:space:]')
          echo "Active connections: $CONNS"
          
          if [ "$CONNS" -eq "0" ]; then
            break
          fi
          
          sleep 2
        done
        
        # Drop the test database
        dropdb -h 127.0.0.1 -U postgres test_save_n_bite_integration_db || true
        
        # Clean up NFR test database
        echo "Cleaning up NFR test database..."
        for i in {1..5}; do
          echo "Attempt $i to terminate NFR database connections..."
          psql -h 127.0.0.1 -U postgres -d postgres -c "SELECT pg_terminate_backend(pid) FROM pg_stat_activity WHERE datname = 'test_nfr_db'" || true
          
          # Check if there are still connections
          CONNS=$(psql -h 127.0.0.1 -U postgres -d postgres -t -c "SELECT count(*) FROM pg_stat_activity WHERE datname = 'test_nfr_db'" | tr -d '[:space:]')
          echo "Active NFR database connections: $CONNS"
          
          if [ "$CONNS" -eq "0" ]; then
            break
          fi
          
          sleep 2
        done
        
        # Drop the NFR test database
        dropdb -h 127.0.0.1 -U postgres test_nfr_db || true
        
        # Final check for both databases
        for db in test_save_n_bite_integration_db test_nfr_db; do
          if psql -h 127.0.0.1 -U postgres -lqt | cut -d \| -f 1 | grep -qw $db; then
            echo "Warning: Failed to drop database $db"
          else
            echo "Successfully cleaned up database $db"
          fi
        done

    # - name: Run coverage report (if requested)
    #   if: ${{ github.event.inputs.run_coverage == 'true' || github.event_name == 'pull_request' }}
    #   run: poetry run pytest --cov=. --cov-report=html --cov-report=term-missing

    - name: Upload coverage reports
      if: ${{ github.event.inputs.run_coverage == 'true' || github.event_name == 'pull_request' }}
      uses: actions/upload-artifact@v4
      with:
        name: coverage-report
        path: save-n-bite-backend/htmlcov/